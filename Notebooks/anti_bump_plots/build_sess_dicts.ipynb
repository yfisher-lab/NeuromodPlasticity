{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "920c8707-1216-4674-a092-1dd140371346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import skimage \n",
    "from glob import glob\n",
    "\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "\n",
    "\n",
    "import SessionTools.two_photon as st2p\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0fb8aa8-5aed-4b7b-a6e6-4b37c5ea003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dict(date, fly, sess, sess_dir,\n",
    "               genotype = \"ER4d_sytjGCaMP7f_EPG_jRGECO1a\",\n",
    "               basedir = pathlib.Path('/media/mplitt/SSD_storage1/2PData')):\n",
    "    basedir = pathlib.Path(basedir.joinpath(genotype))\n",
    "    \n",
    "    basename_input = pathlib.Path(sess_dir.joinpath(sess))\n",
    "    metadata = st2p.preprocessing.bruker_metadata.read(basename_input)\n",
    "\n",
    "    h5name = f'/media/mplitt/SSD_storage1/2P_scratch/{genotype}/{date}/{fly}/{sess}/data.h5'\n",
    "    if not os.path.exists(h5name):\n",
    "        return None\n",
    "        # tiff_data = st2p.preprocessing.tiff_tools.read(basename_input, \n",
    "        #                                             metadata['size'],metadata['layout'], first_chan=1)\n",
    "        # st2p.preprocessing.tiff_tools.convert_to_hdf5(tiff_data,h5name, overwrite=True)\n",
    "    napari_outputs_file = f'/media/mplitt/SSD_storage1/2P_scratch/{genotype}/{date}/{fly}/{sess}/napari.pkl'\n",
    "    if not os.path.exists(napari_outputs_file):\n",
    "        return None\n",
    "                \n",
    "    f = h5py.File(h5name)\n",
    "    data = f['/data'][:]\n",
    "\n",
    "    ref_img = st2p.preprocessing.motion_correction.make_ref_img(data,0)\n",
    "    data_corr, shifts, error, diffphase = st2p.preprocessing.motion_correction.align_data_chunk(data, \n",
    "                                                                                                ref_img[0,:,:,:], \n",
    "                                                                                                in_place=False)\n",
    "\n",
    "    napari_outputs_file = f'/media/mplitt/SSD_storage1/2P_scratch/{genotype}/{date}/{fly}/{sess}/napari.pkl'\n",
    "    if not os.path.exists(napari_outputs_file):\n",
    "        return None\n",
    "    \n",
    "    with open(napari_outputs_file, 'rb') as file:\n",
    "        np_layers = cloudpickle.load(file)\n",
    "    print(np_layers.keys())\n",
    "                    \n",
    "    masks_EB = np_layers['rois_EB']\n",
    "    masks_R4d = np_layers['rois_R4d']\n",
    "    bckgnd = np_layers['background']\n",
    "                \n",
    "        \n",
    "        \n",
    "    csv_files = glob(f'/media/mplitt/SSD_storage1/2PData/{genotype}/{date}/{fly}/{sess}/*.csv')\n",
    "    vr_file = pathlib.Path(csv_files[0])\n",
    "    df = dd.read_csv(vr_file).compute()\n",
    "\n",
    "    frame_times = np.array(metadata['frame_times']).mean(axis=-1)*1000\n",
    "    df_aligned = st2p.preprocessing.signals.align_vr_2p(df,frame_times)\n",
    "\n",
    "    # remove VR artifact\n",
    "    F_EB, notF_EB = st2p.preprocessing.signals.extract_2p_timeseries(data_corr, masks_EB, 16, bckgnd_mask = bckgnd, max_proj=False) \n",
    "    F_R4d, notF_R4d = st2p.preprocessing.signals.extract_2p_timeseries(data_corr, masks_R4d, 16, bckgnd_mask = bckgnd, max_proj=False) \n",
    "    \n",
    "    F_EB_bcorr = 0*F_EB\n",
    "    F_R4d_bcorr = 0*F_R4d\n",
    "    for ch in range(F_EB.shape[0]):\n",
    "        lr = LinReg().fit(notF_EB[ch,np.newaxis, :].T, F_EB[ch,:,:].T)\n",
    "        F_EB_bcorr[ch,:,:] = F_EB[ch,:,:]-lr.predict(notF_EB[ch,np.newaxis,:].T).T \n",
    "        \n",
    "        lr = LinReg().fit(notF_R4d[ch,np.newaxis, :].T, F_R4d[ch,:,:].T)\n",
    "        F_R4d_bcorr[ch,:,:] = F_R4d[ch,:,:]-lr.predict(notF_R4d[ch,np.newaxis,:].T).T \n",
    "    \n",
    "    F_EB_bleed = 0*F_EB\n",
    "    F_R4d_bleed = 0*F_R4d\n",
    "    lr = LinReg().fit(F_EB_bcorr[1,:, :].T, F_EB_bcorr[0,:,:].T)\n",
    "    F_EB_bleed[ch,:,:] = F_EB_bcorr[0,:,:]-1.*lr.predict(F_EB_bcorr[1,:,:].T).T \n",
    "        \n",
    "    lr = LinReg().fit(F_R4d_bcorr[0,:, :].T, F_R4d_bcorr[1,:,:].T)\n",
    "    F_R4d_bleed[ch,:,:] = F_R4d_bcorr[1,:,:]-1,*lr.predict(F_R4d_bcorr[0,:,:].T).T \n",
    "    \n",
    "        \n",
    "    \n",
    "    F_EB_sm = sp.ndimage.gaussian_filter1d(F_EB_bleed,2,axis=-1)\n",
    "    F_EB_sm = sp.ndimage.gaussian_filter1d(F_EB_sm,1.5,axis=1, mode='wrap')\n",
    "    \n",
    "    F_R4d_sm = sp.ndimage.gaussian_filter1d(F_R4d_bleed,2,axis=-1)\n",
    "    F_R4d_sm = sp.ndimage.gaussian_filter1d(F_R4d_sm,1.5,axis=1, mode='wrap')\n",
    "\n",
    "    dff_EB = sp.stats.zscore(F_EB_sm[0,:,:],axis=-1)\n",
    "    dff_R4d = sp.stats.zscore(F_R4d_sm[1,:,:],axis=-1)\n",
    "\n",
    "    heading = np.angle(np.exp(1j*(np.pi-df_aligned[' Heading'].to_numpy().ravel())))\n",
    "\n",
    "    bin_centers =  np.linspace(-np.pi, np.pi, num=16)[:,np.newaxis]\n",
    "    dff_EB_complex = dff_EB*np.cos(bin_centers) + 1j*dff_EB*np.sin(bin_centers)\n",
    "    rho_EB, phi_EB = np.abs(dff_EB_complex.mean(axis=0)), np.angle(dff_EB_complex.mean(axis=0))\n",
    "    \n",
    "    dff_R4d_complex = dff_R4d*np.cos(bin_centers) + 1j*dff_R4d*np.sin(bin_centers)\n",
    "    rho_R4d, phi_R4d = np.abs(dff_R4d_complex.mean(axis=0)), np.angle(dff_R4d_complex.mean(axis=0))\n",
    "\n",
    "    data = {'fly': fly,\n",
    "            'date': date,\n",
    "            'session': sess,\n",
    "            'F_EB': F_EB,\n",
    "            'not_F_EB': notF_EB,\n",
    "            'F_EB_bcorr':F_EB_bcorr,\n",
    "            'F_EB_bleed': F_EB_bleed,\n",
    "            'F_EB_sm': F_EB_sm,\n",
    "            'F_R4d': F_R4d,\n",
    "            'not_F_R4d': notF_R4d,\n",
    "            'F_R4d_bcorr':F_R4d_bcorr,\n",
    "            'F_R4d_bleed': F_R4d_bleed,\n",
    "            'F_R4d_sm': F_R4d_sm,\n",
    "            'df_aligned': df_aligned,\n",
    "            'dff_EB': dff_EB,\n",
    "            'dff_R4d': dff_R4d,\n",
    "            'heading': heading,\n",
    "            'bin_centers': bin_centers,\n",
    "            'dff_EB_complex': dff_EB_complex,\n",
    "            'dff_R4d_complex': dff_R4d_complex,\n",
    "            'rho_EB': rho_EB,\n",
    "            'phi_EB': phi_EB,\n",
    "            'rho_R4d': rho_R4d,\n",
    "            'phi_R4d': phi_R4d}\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23a0141-e12a-4c8b-ba54-2baa67212da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Skipping final stack because it was found with fewer z-planes (5, expected: 8).\n",
      "WARNING:root:Skipping final stack because it was found with fewer z-planes (3, expected: 8).\n",
      "WARNING:root:Skipping final stack because it was found with fewer z-planes (6, expected: 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ref_ch1', 'ref_ch1_maxp', 'ref_ch2', 'ref_ch2_maxp', 'inner_ring', 'outer_ring_EB', 'outer_ring_R4d', 'background', 'rois_EB', 'rois_R4d', 'n_ch', 'ref_img'])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "06_08_2023 fly1 baseline-004\n"
     ]
    }
   ],
   "source": [
    "genotype = \"ER4d_sytjGCaMP7f_EPG_jRGECO1a\"\n",
    "basedir = pathlib.Path(f'/media/mplitt/SSD_storage1/2PData/{genotype}')\n",
    "\n",
    "for date_dir in basedir.glob('*'):\n",
    "    date = date_dir.stem\n",
    "    for fly_dir in date_dir.glob('fly*'): \n",
    "        fly = fly_dir.stem\n",
    "        \n",
    "        for sess_dir in fly_dir.glob(\"*\"):\n",
    "            if sess_dir.is_dir() and \"SingleImage\" not in sess_dir.stem:\n",
    "                sess = sess_dir.stem\n",
    "                \n",
    "                sess_pkl_dir = f'/media/mplitt/SSD_storage1/2P_scratch/{genotype}/{date}/{fly}/{sess}/data.pkl'\n",
    "                if not os.path.exists(sess_pkl_dir):\n",
    "                    # print(date, fly, sess)\n",
    "                    try:\n",
    "                        data = build_dict(date, fly, sess, sess_dir)\n",
    "\n",
    "                        if data is not None:\n",
    "                            try:\n",
    "                                with open(sess_pkl_dir, 'wb') as file:\n",
    "                                    cloudpickle.dump(data, file)\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        print(date, fly, sess)\n",
    "                        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a712a761-223b-4352-922b-6d7f2a24272a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_08_2023 fly2 baseline-000\n",
      "11_08_2023 fly2 open_loop-001\n",
      "11_08_2023 fly1 baseline-000\n",
      "11_08_2023 fly3 baseline-000\n",
      "11_08_2023 fly3 open_loop-002\n",
      "10_10_2023 fly1 baseline-000\n",
      "10_10_2023 fly1 baseline-001\n",
      "30_10_2023 fly2 closed_loop-000\n",
      "30_10_2023 fly2 closed_loop-001\n",
      "30_10_2023 fly1 closed_loop-000\n",
      "30_10_2023 fly1 closed_loop-003\n",
      "30_10_2023 fly1 closed_loop-001\n",
      "30_10_2023 fly3 closed_loop-000\n",
      "06_11_2023 fly1 closed_loop-002\n",
      "06_11_2023 fly1 closed_loop-000\n",
      "06_08_2023 fly2 baseline-001\n",
      "07_08_2023 fly1 baseline-000\n",
      "07_08_2023 fly3 baseline-000\n",
      "07_08_2023 fly3 baseline-001\n",
      "12_10_2023 fly2 baseline-000\n",
      "12_10_2023 fly2 baseline-001\n",
      "12_10_2023 fly2 baseline_to_dark-002\n",
      "12_10_2023 fly3 baseline-000\n",
      "12_10_2023 fly3 baseline-001\n",
      "11_10_2023 fly6 baseline-001\n",
      "11_10_2023 fly5 baseline-000\n",
      "11_10_2023 fly2 baseline-000\n",
      "11_10_2023 fly2 baseline-001\n",
      "11_10_2023 fly7 baseline-000\n",
      "11_10_2023 fly7 baseline-001\n",
      "11_10_2023 fly7 baseline_to_dark-002\n",
      "11_10_2023 fly4 baseline_open_loop-002\n",
      "31_10_2023 fly5 closed_loop-001\n",
      "31_10_2023 fly2 closed_loop-000\n",
      "31_10_2023 fly1 closed_loop-000\n",
      "31_10_2023 fly4 closed_loop_to_dark-002\n",
      "31_10_2023 fly4 closed_loop-000\n",
      "31_10_2023 fly4 closed_loop-001\n",
      "28_10_2023 fly2 closed_loop-003\n",
      "28_10_2023 fly2 closed_loop-001\n",
      "28_10_2023 fly1 closed_loop-000\n",
      "28_10_2023 fly3 closed_loop-000\n",
      "28_10_2023 fly3 closed_loop-001\n"
     ]
    }
   ],
   "source": [
    "genotype = \"ER4d_sytjGCaMP7f_EPG_jRGECO1a\"\n",
    "basedir = pathlib.Path(f'/media/mplitt/SSD_storage1/2PData/{genotype}')\n",
    "\n",
    "for date_dir in basedir.glob('*'):\n",
    "    date = date_dir.stem\n",
    "    for fly_dir in date_dir.glob('fly*'): \n",
    "        fly = fly_dir.stem\n",
    "        \n",
    "        for sess_dir in fly_dir.glob(\"*\"):\n",
    "            if sess_dir.is_dir() and \"SingleImage\" not in sess_dir.stem:\n",
    "                sess = sess_dir.stem\n",
    "                \n",
    "                sess_pkl_dir = f'/media/mplitt/SSD_storage/2P_scratch/{genotype}/{date}/{fly}/{sess}/data.pkl'\n",
    "                if os.path.exists(sess_pkl_dir):\n",
    "                    print(date, fly, sess)\n",
    "                    with open(sess_pkl_dir, 'rb') as file:\n",
    "                        data = cloudpickle.load(file)\n",
    "                           \n",
    "    \n",
    "                    F_EB_bcorr, F_R4d_bcorr = data['F_EB_bcorr'], data['F_R4d_bcorr']\n",
    "                    F_EB_bleed = 0*F_EB_bcorr\n",
    "                    F_R4d_bleed = 0*F_R4d_bcorr\n",
    "                    lr = LinReg().fit(F_EB_bcorr[1,:, :].T, F_EB_bcorr[0,:,:].T)\n",
    "                    F_EB_bleed[0,:,:] = F_EB_bcorr[0,:,:]-1.*lr.predict(F_EB_bcorr[1,:,:].T).T \n",
    "\n",
    "                    lr = LinReg().fit(F_R4d_bcorr[0,:, :].T, F_R4d_bcorr[1,:,:].T)\n",
    "                    F_R4d_bleed[1,:,:] = F_R4d_bcorr[1,:,:]-1.*lr.predict(F_R4d_bcorr[0,:,:].T).T \n",
    "                    \n",
    "                    data['F_EB_bleed']=F_EB_bleed\n",
    "                    data['F_R4d_bleed']=F_R4d_bleed\n",
    "                    \n",
    "                    \n",
    "                    F_EB_sm = sp.ndimage.gaussian_filter1d(F_EB_bleed,2,axis=-1)\n",
    "                    F_EB_sm = sp.ndimage.gaussian_filter1d(F_EB_sm,1.,axis=1, mode='wrap')\n",
    "                    \n",
    "                    data['F_EB_sm']=F_EB_sm\n",
    "    \n",
    "                    F_R4d_sm = sp.ndimage.gaussian_filter1d(F_R4d_bleed,2,axis=-1)\n",
    "                    F_R4d_sm = sp.ndimage.gaussian_filter1d(F_R4d_sm,1.,axis=1, mode='wrap')\n",
    "            \n",
    "                    data['F_R4d_sm']=F_R4d_sm\n",
    "\n",
    "                    dff_R4d = sp.stats.zscore(F_R4d_sm[1,:,:],axis=-1)#/np.linalg.norm(F_R4d_sm[1,:,:], axis=0, keepdims=True)\n",
    "                    dff_EB = sp.stats.zscore(F_EB_sm[0,:,:],axis=-1)#/np.linalg.norm(F_EB_sm[0,:,:], axis=0, keepdims=True)\n",
    "                    \n",
    "                    data['dff_EB']=dff_EB\n",
    "                    data['dff_R4d']=dff_R4d\n",
    "\n",
    "                    heading = data['heading']\n",
    "                    \n",
    "\n",
    "                    bin_centers =  np.linspace(-np.pi, np.pi, num=16)[:,np.newaxis]\n",
    "                    dff_EB_complex = dff_EB*np.cos(bin_centers) + 1j*dff_EB*np.sin(bin_centers)\n",
    "                    rho_EB, phi_EB = np.abs(dff_EB_complex.mean(axis=0)), np.angle(dff_EB_complex.mean(axis=0))\n",
    "\n",
    "                    data['dff_EB_complex']=dff_EB_complex\n",
    "                    data['rho_EB']=rho_EB\n",
    "                    data['phi_EB']=phi_EB\n",
    "                    \n",
    "                    dff_R4d_complex = dff_R4d*np.cos(bin_centers) + 1j*dff_R4d*np.sin(bin_centers)\n",
    "                    rho_R4d, phi_R4d = np.abs(dff_R4d_complex.mean(axis=0)), np.angle(dff_R4d_complex.mean(axis=0))\n",
    "                    \n",
    "                    data['dff_R4d_complex']=dff_R4d_complex\n",
    "                    data['rho_R4d']=rho_R4d\n",
    "                    data['phi_R4d']=phi_R4d\n",
    "                    \n",
    "                    with open(sess_pkl_dir,'wb') as file:\n",
    "                        cloudpickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b49ea-fbc1-470d-b95c-049ab705411e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
