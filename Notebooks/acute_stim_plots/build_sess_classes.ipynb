{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f48230c-5acf-4bf5-ba63-33991a082717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import skimage \n",
    "from glob import glob\n",
    "\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "\n",
    "\n",
    "import SessionTools.two_photon as st2p\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9885fa35-0467-4916-9760-19d5b251efdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "genotype = \"R60D05LexA_jGCaMP7f_EL_CsChrimsontdT\"\n",
    "basedir = pathlib.Path(f'/media/mplitt/SSD_storage/2PData/{genotype}')\n",
    "\n",
    "for date_dir in basedir.glob('*'):\n",
    "    date = date_dir.stem\n",
    "    for fly_dir in date_dir.glob('fly*'): \n",
    "        fly = fly_dir.stem\n",
    "        \n",
    "        for sess_dir in fly_dir.glob(\"*\"):\n",
    "            if sess_dir.is_dir() and \"SingleImage\" not in sess_dir.stem:\n",
    "                sess = sess_dir.stem\n",
    "                \n",
    "                basename_input = pathlib.Path(sess_dir.joinpath(sess))\n",
    "                metadata = st2p.preprocessing.bruker_metadata.read(basename_input)\n",
    "\n",
    "                h5name = f'/media/mplitt/SSD_storage/2P_scratch/{genotype}/{date}/{fly}/{sess}/data.h5'\n",
    "                if not os.path.exists(h5name):\n",
    "                    tiff_data = st2p.preprocessing.tiff_tools.read(basename_input, \n",
    "                                                            metadata['size'],metadata['layout'], first_chan=1)\n",
    "                    st2p.preprocessing.tiff_tools.convert_to_hdf5(tiff_data,h5name, overwrite=True)\n",
    "            \n",
    "                \n",
    "                f = h5py.File(h5name)\n",
    "                data = f['/data'][:]\n",
    "\n",
    "                ref_img = st2p.preprocessing.motion_correction.make_ref_img(data,0)\n",
    "                data_corr, shifts, error, diffphase = st2p.preprocessing.motion_correction.align_data_chunk(data, \n",
    "                                                                                                            ref_img[0,:,:,:], \n",
    "                                                                                                            in_place=False)\n",
    "\n",
    "                napari_outputs_file = f'/media/mplitt/SSD_storage/2P_scratch/{genotype}/{date}/{fly}/{sess}/napari.pkl'\n",
    "\n",
    "                with open(napari_outputs_file, 'rb') as file:\n",
    "                    np_layers = cloudpickle.load(file)\n",
    "                masks = np_layers['rois']\n",
    "                bckgnd = np_layers['background']\n",
    "\n",
    "                csv_files = glob(f'/media/mplitt/SSD_storage/2PData/{genotype}/{date}/{fly}/{sess}/*.csv')\n",
    "                vr_file = pathlib.Path(csv_files[0])\n",
    "                df = dd.read_csv(vr_file).compute()\n",
    "\n",
    "                frame_times = np.array(metadata['frame_times']).mean(axis=-1)*1000\n",
    "                df_aligned = st2p.preprocessing.signals.align_vr_2p(df,frame_times)\n",
    "\n",
    "                F, notF = st2p.preprocessing.signals.extract_2p_timeseries(data_corr, masks, 16, bckgnd_mask = bckgnd, max_proj=False) \n",
    "                F_bleed_corr = 0*F\n",
    "                for ch in range(F.shape[0]):\n",
    "                    lr = LinReg().fit(notF[ch,np.newaxis, :].T, F[ch,:,:].T)\n",
    "                    F_bleed_corr[ch,:,:] = F[ch,:,:]-lr.predict(notF[ch,np.newaxis,:].T).T  \n",
    "\n",
    "                F_sm = sp.ndimage.gaussian_filter1d(F_bleed_corr,1.5,axis=-1)\n",
    "                F_sm = sp.ndimage.gaussian_filter1d(F_sm,.5,axis=1, mode='wrap')\n",
    "\n",
    "                dff = sp.stats.zscore(F_sm[1,:,:],axis=-1)\n",
    "\n",
    "                heading = np.angle(np.exp(1j*(np.pi-df_aligned[' Heading'].to_numpy().ravel())))\n",
    "\n",
    "                bin_centers =  np.linspace(-np.pi, np.pi, num=16)[:,np.newaxis]\n",
    "                dff_complex = dff*np.cos(bin_centers) + 1j*dff*np.sin(bin_centers)\n",
    "                rho, phi = np.abs(dff_complex.mean(axis=0)), np.angle(dff_complex.mean(axis=0))\n",
    "                \n",
    "                data = {'fly': fly,\n",
    "                        'date': date,\n",
    "                        'session': sess,\n",
    "                        'F': F,\n",
    "                        'not_F': notF,\n",
    "                        'F_bleed_corr':F_bleed_corr,\n",
    "                        'F_sm': F_sm,\n",
    "                        'df_aligned': df_aligned,\n",
    "                        'dff': dff,\n",
    "                        'heading': heading,\n",
    "                        'bin_centers': bin_centers,\n",
    "                        'dff_complex': dff_complex,\n",
    "                        'rho': rho,\n",
    "                        'phi': phi}\n",
    "                sess_pkl_dir = f'/media/mplitt/SSD_storage/2P_scratch/{genotype}/{date}/{fly}/{sess}/sess.pkl'\n",
    "                with open(sess_pkl_dir, 'wb') as file:\n",
    "                    cloudpickle.dump(data, file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a0ae2c-2fb6-4ad5-a7a5-c17c3ee7ba46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.5+1.5j)\n"
     ]
    }
   ],
   "source": [
    "a = [2 + 2j , 1 + 1j]\n",
    "print(np.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11df13d7-9f27-4239-8128-cbeb27b2a520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/mplitt/SSD_storage/2PData/R60D05LexA_jGCaMP7f_EL_CsChrimsontdT/02_11_2023', '/media/mplitt/SSD_storage/2PData/R60D05LexA_jGCaMP7f_EL_CsChrimsontdT/17_10_2023', '/media/mplitt/SSD_storage/2PData/R60D05LexA_jGCaMP7f_EL_CsChrimsontdT/31_10_2023']\n"
     ]
    }
   ],
   "source": [
    "dates = glob(basedir + '/*')\n",
    "print(dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
